#!/usr/bin/env python3
"""
ìš°ì„ ìˆœìœ„ ê¸°ë°˜ liteLLM API ì‹œìŠ¤í…œì„ ê²€ì¦í•˜ëŠ” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ API í‚¤ í´ë°± ë° ëª¨ë¸ ì„ íƒì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:
1. OPENROUTER_API_KEY â†’ google/gemini-2.5-flash
2. GEMINI_API_KEY â†’ gemini/gemini-2.5-flash  
3. OPENAI_API_KEY â†’ gpt-4.1-mini
4. ANTHROPIC_API_KEY â†’ claude-3-5-haiku-latest
"""
import os
import sys
import logging
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

from config.config import Config

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_api_key_configuration():
    """API í‚¤ êµ¬ì„± ë° ìš°ì„ ìˆœìœ„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ” Testing API key configuration...")
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    api_keys = {
        'OPENROUTER_API_KEY': os.getenv('OPENROUTER_API_KEY', ''),
        'GEMINI_API_KEY': os.getenv('GEMINI_API_KEY', ''),
        'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY', ''),
        'ANTHROPIC_API_KEY': os.getenv('ANTHROPIC_API_KEY', '')
    }
    
    logger.info("Available API keys:")
    for key, value in api_keys.items():
        status = "âœ… SET" if value else "âŒ NOT SET"
        logger.info(f"  {key}: {status}")
    
    if not any(api_keys.values()):
        logger.error("âŒ No API keys found in environment variables")
        logger.info("ğŸ’¡ Copy .env.example to .env and add your API keys")
        return False
    
    return True

def test_priority_system():
    """ìš°ì„ ìˆœìœ„ ê¸°ë°˜ êµ¬ì„± ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    logger.info("\nğŸ¯ Testing priority-based configuration system...")
    
    try:
        config = Config()
        
        # ê¸°ë³¸ ì„¤ì • í…ŒìŠ¤íŠ¸
        primary_config = config.get_llm_config()
        if primary_config:
            logger.info(f"âœ… Primary configuration: {primary_config['provider']} â†’ {primary_config['model']}")
        else:
            logger.warning("âš ï¸ Primary configuration is not available")
        
        # ëª¨ë“  ì‚¬ìš© ê°€ëŠ¥í•œ ì„¤ì • í…ŒìŠ¤íŠ¸
        all_configs = config.get_all_available_llm_configs()
        logger.info(f"ğŸ“Š Total available configurations: {len(all_configs)}")
        
        expected_priority = [
            ("OpenRouter", "google/gemini-2.5-flash"),
            ("Gemini", "gemini/gemini-2.5-flash"),
            ("OpenAI", "gpt-4.1-mini"),
            ("Anthropic", "claude-3-5-haiku-latest")
        ]
        
        for idx, config_item in enumerate(all_configs):
            provider = config_item['provider']
            model = config_item['model']
            priority = idx + 1
            
            logger.info(f"  {priority}. {provider} â†’ {model}")
            
            # ì˜ˆìƒ ìš°ì„ ìˆœìœ„ ìˆœì„œ í™•ì¸
            if idx < len(expected_priority):
                expected_provider, expected_model = expected_priority[idx]
                if provider == expected_provider and model == expected_model:
                    logger.info(f"    âœ… Priority {priority} matches expected configuration")
                else:
                    logger.warning(f"    âš ï¸ Priority {priority} differs from expected: {expected_provider} â†’ {expected_model}")
        
        return len(all_configs) > 0
        
    except Exception as e:
        logger.error(f"âŒ Priority system test error: {str(e)}")
        return False

def test_model_naming():
    """ëª¨ë¸ ì´ë¦„ì´ ì •í™•í•œ ìš”êµ¬ì‚¬í•­ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸"""
    logger.info("\nğŸ·ï¸ Testing model naming conventions...")
    
    try:
        config = Config()
        all_configs = config.get_all_available_llm_configs()
        
        expected_models = {
            "OpenRouter": "google/gemini-2.5-flash",
            "Gemini": "gemini/gemini-2.5-flash",
            "OpenAI": "gpt-4.1-mini",
            "Anthropic": "claude-3-5-haiku-latest"
        }
        
        for config_item in all_configs:
            provider = config_item['provider']
            model = config_item['model']
            
            if provider in expected_models:
                expected_model = expected_models[provider]
                if model == expected_model:
                    logger.info(f"âœ… {provider} model name correct: {model}")
                else:
                    logger.error(f"âŒ {provider} model name incorrect: {model} (expected: {expected_model})")
            else:
                logger.warning(f"âš ï¸ Unknown provider: {provider}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Model naming test error: {str(e)}")
        return False

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    logger.info("ğŸš€ Starting priority-based liteLLM system test")
    logger.info("=" * 60)
    
    tests = [
        ("API Key Configuration", test_api_key_configuration),
        ("Priority System", test_priority_system),
        ("Model Naming", test_model_naming)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            logger.error(f"âŒ {test_name} failed due to exception: {str(e)}")
            results.append((test_name, False))
    
    # ìš”ì•½
    logger.info("\nğŸ“‹ Test results summary:")
    logger.info("=" * 60)
    
    passed = 0
    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        logger.info(f"{status}: {test_name}")
        if result:
            passed += 1
    
    logger.info(f"\nğŸ† Passed tests: {passed}/{len(results)}")
    
    if passed == len(results):
        logger.info("ğŸ‰ All tests passed! Priority-based liteLLM system is working correctly.")
        return True
    else:
        logger.error("âŒ Some tests failed. Please check your configuration.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)